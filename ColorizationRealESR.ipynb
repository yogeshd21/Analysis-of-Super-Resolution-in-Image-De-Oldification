{"cells":[{"cell_type":"markdown","source":["## Import Dependencies"],"metadata":{"id":"Rd4144yqpUbh"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive/')\n","os.chdir('/content/drive/My Drive/DL_FinalProject/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTxiSDQIEGhH","executionInfo":{"status":"ok","timestamp":1651858689910,"user_tz":240,"elapsed":21682,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"8175de71-ecf7-4ec8-e44a-60426008be5a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["#install fastai to use Dynamic Unet model\n","!pip install fastai==2.4\n","\n","# Set up the environment for Real ESRGAN model\n","!pip install basicsr\n","!pip install facexlib\n","!pip install gfpgan\n","\n","# Download the pre-trained Real ESRGAN model and save it to \"experiments/pretrained_models\"\n","!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"V6dyQYxO7aVj","executionInfo":{"status":"ok","timestamp":1651858816352,"user_tz":240,"elapsed":124283,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"a3edb85b-00b6-4ca1-f544-4a67fb29ea71"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fastai==2.4\n","  Downloading fastai-2.4-py3-none-any.whl (187 kB)\n","\u001b[K     |████████████████████████████████| 187 kB 655 kB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (3.2.2)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (0.12.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (2.23.0)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (1.0.2)\n","Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (7.1.2)\n","Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (2.2.4)\n","Collecting fastcore<1.4,>=1.3.8\n","  Downloading fastcore-1.3.29-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 2.9 MB/s \n","\u001b[?25hCollecting torch<1.10,>=1.7.0\n","  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 6.6 kB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (1.3.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (1.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (3.13)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (1.4.1)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.4) (21.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (0.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (0.9.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (1.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (57.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (1.1.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (4.64.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (1.0.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (3.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (1.21.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai==2.4) (2.0.6)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai==2.4) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai==2.4) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai==2.4) (4.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.4) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.4) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.4) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.4) (3.0.4)\n","Collecting torchvision>=0.8.2\n","  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[K     |████████████████████████████████| 21.0 MB 213 kB/s \n","\u001b[?25h  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 130 kB/s \n","\u001b[?25h  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n","\u001b[K     |████████████████████████████████| 23.3 MB 1.2 MB/s \n","\u001b[?25h  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n","\u001b[K     |████████████████████████████████| 23.3 MB 1.1 MB/s \n","\u001b[?25h  Downloading torchvision-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.4) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.4) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.4) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.4) (3.0.8)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai==2.4) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.4) (2022.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.4) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.4) (1.1.0)\n","Installing collected packages: torch, torchvision, fastcore, fastai\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.12.0+cu113\n","    Uninstalling torchvision-0.12.0+cu113:\n","      Successfully uninstalled torchvision-0.12.0+cu113\n","  Attempting uninstall: fastai\n","    Found existing installation: fastai 1.0.61\n","    Uninstalling fastai-1.0.61:\n","      Successfully uninstalled fastai-1.0.61\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n","Successfully installed fastai-2.4 fastcore-1.3.29 torch-1.9.1 torchvision-0.10.1\n","Collecting basicsr\n","  Downloading basicsr-1.3.5.tar.gz (161 kB)\n","\u001b[K     |████████████████████████████████| 161 kB 655 kB/s \n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.16.0)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.99)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.21.6)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from basicsr) (4.1.2.30)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from basicsr) (7.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from basicsr) (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from basicsr) (2.23.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.18.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.4.1)\n","Collecting tb-nightly\n","  Downloading tb_nightly-2.10.0a20220506-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 4.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.9.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from basicsr) (4.64.0)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 72.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->basicsr) (4.2.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (2021.10.8)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2021.11.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (3.2.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2.6.3)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2.4.1)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (1.3.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (1.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (1.15.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.4.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.44.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.35.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.0.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.8.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly->basicsr) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->basicsr) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (3.2.0)\n","Building wheels for collected packages: basicsr\n","  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for basicsr: filename=basicsr-1.3.5-py3-none-any.whl size=194483 sha256=2d260784553fc97245be667065da6eaffe22a3491285aa4d7e2b9753e410c083\n","  Stored in directory: /root/.cache/pip/wheels/74/1b/d0/8659cf028233dd1e3bf282271009fbf037dfc4ab761f32a032\n","Successfully built basicsr\n","Installing collected packages: yapf, tb-nightly, addict, basicsr\n","Successfully installed addict-2.4.0 basicsr-1.3.5 tb-nightly-2.10.0a20220506 yapf-0.32.0\n","Collecting facexlib\n","  Downloading facexlib-0.2.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 639 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facexlib) (1.21.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from facexlib) (7.1.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from facexlib) (1.9.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from facexlib) (4.1.2.30)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from facexlib) (0.51.2)\n","Collecting filterpy\n","  Downloading filterpy-1.4.5.zip (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facexlib) (0.10.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from facexlib) (1.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from facexlib) (4.64.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from filterpy->facexlib) (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->filterpy->facexlib) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy->facexlib) (1.15.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->facexlib) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->facexlib) (57.4.0)\n","Building wheels for collected packages: filterpy\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110474 sha256=ab42704ec7fb57c528dbfc062aa18c8d5a4b52ba936d0cc572e88f4a3d8d6151\n","  Stored in directory: /root/.cache/pip/wheels/ce/e0/ee/a2b3c5caab3418c1ccd8c4de573d4cbe13315d7e8b0a55fbc2\n","Successfully built filterpy\n","Installing collected packages: filterpy, facexlib\n","Successfully installed facexlib-0.2.2 filterpy-1.4.5\n","Collecting gfpgan\n","  Downloading gfpgan-1.3.2-py3-none-any.whl (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 443 kB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.10.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gfpgan) (4.1.2.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gfpgan) (4.64.0)\n","Collecting numpy<1.21\n","  Downloading numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n","\u001b[K     |████████████████████████████████| 15.3 MB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: tb-nightly in /usr/local/lib/python3.7/dist-packages (from gfpgan) (2.10.0a20220506)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.99)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from gfpgan) (1.9.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gfpgan) (3.13)\n","Requirement already satisfied: facexlib>=0.2.0.3 in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.2.2)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.32.0)\n","Requirement already satisfied: basicsr>=1.3.4.0 in /usr/local/lib/python3.7/dist-packages (from gfpgan) (1.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gfpgan) (1.4.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from basicsr>=1.3.4.0->gfpgan) (7.1.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from basicsr>=1.3.4.0->gfpgan) (0.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from basicsr>=1.3.4.0->gfpgan) (2.23.0)\n","Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from basicsr>=1.3.4.0->gfpgan) (2.4.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from basicsr>=1.3.4.0->gfpgan) (0.18.3)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from facexlib>=0.2.0.3->gfpgan) (0.51.2)\n","Requirement already satisfied: filterpy in /usr/local/lib/python3.7/dist-packages (from facexlib>=0.2.0.3->gfpgan) (1.4.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->gfpgan) (4.2.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from filterpy->facexlib>=0.2.0.3->gfpgan) (3.2.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->gfpgan) (3.0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->gfpgan) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->gfpgan) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->gfpgan) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy->facexlib>=0.2.0.3->gfpgan) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->facexlib>=0.2.0.3->gfpgan) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->facexlib>=0.2.0.3->gfpgan) (0.34.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr>=1.3.4.0->gfpgan) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr>=1.3.4.0->gfpgan) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr>=1.3.4.0->gfpgan) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr>=1.3.4.0->gfpgan) (1.24.3)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr>=1.3.4.0->gfpgan) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr>=1.3.4.0->gfpgan) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr>=1.3.4.0->gfpgan) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr>=1.3.4.0->gfpgan) (1.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (3.17.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.44.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.0.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (3.3.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->gfpgan) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly->gfpgan) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->gfpgan) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->gfpgan) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->gfpgan) (3.2.0)\n","Installing collected packages: numpy, gfpgan\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed gfpgan-1.3.2 numpy-1.20.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["--2022-05-06 17:40:12--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n","Resolving github.com (github.com)... 52.192.72.89\n","Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220506T174013Z&X-Amz-Expires=300&X-Amz-Signature=525d3700285063f0eba8c9f6a15e75c6890290cb3f36dce66b76ace5b1e1b919&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream [following]\n","--2022-05-06 17:40:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220506T174013Z&X-Amz-Expires=300&X-Amz-Signature=525d3700285063f0eba8c9f6a15e75c6890290cb3f36dce66b76ace5b1e1b919&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 67040989 (64M) [application/octet-stream]\n","Saving to: ‘experiments/pretrained_models/RealESRGAN_x4plus.pth.2’\n","\n","RealESRGAN_x4plus.p 100%[===================>]  63.93M  30.3MB/s    in 2.1s    \n","\n","2022-05-06 17:40:15 (30.3 MB/s) - ‘experiments/pretrained_models/RealESRGAN_x4plus.pth.2’ saved [67040989/67040989]\n","\n"]}]},{"cell_type":"code","source":["import os\n","import glob\n","import time\n","import numpy as np\n","from PIL import Image, ImageOps\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","from skimage.color import rgb2lab, lab2rgb\n","\n","import torch\n","from torch import nn, optim\n","from torchvision import transforms\n","from torchvision.utils import make_grid\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","from fastai.vision.learner import create_body\n","from torchvision.models.resnet import resnet18\n","from fastai.vision.models.unet import DynamicUnet\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","use_colab = None\n","\n","import os.path as osp\n","import glob\n","import cv2\n","import numpy as np\n","import torch"],"metadata":{"id":"fpDkGqiJn066","executionInfo":{"status":"ok","timestamp":1651858818124,"user_tz":240,"elapsed":1781,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Download Data"],"metadata":{"id":"teu1I-Ropt28"}},{"cell_type":"code","source":["from fastai.data.external import untar_data, URLs\n","coco_path = untar_data(URLs.COCO_SAMPLE)\n","coco_path = str(coco_path) + \"/train_sample\"\n","use_colab = True"],"metadata":{"id":"5HIbIprToFb9","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1651859088728,"user_tz":240,"elapsed":217006,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"4e13a3a7-6e54-4092-ee4c-7119c4f859a0"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[""]},"metadata":{}}]},{"cell_type":"markdown","source":["Splitting data into training and validation data"],"metadata":{"id":"EPPO-SrHp_Y7"}},{"cell_type":"code","source":["if use_colab == True:\n","    path = coco_path\n","else:\n","    path = \"./train/\"\n","    \n","paths = glob.glob(path + \"/*.jpg\") # Grabbing all the image file names\n","np.random.seed(123)\n","paths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 10,000 images randomly\n","rand_idxs = np.random.permutation(10_000)\n","train_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\n","val_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\n","train_paths = paths_subset[train_idxs]\n","val_paths = paths_subset[val_idxs]\n","print(len(train_paths), len(val_paths))"],"metadata":{"id":"KTiAerb1oLi8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651859098003,"user_tz":240,"elapsed":270,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"cef77c0e-4675-460b-ea9e-03e703a967c9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["8000 2000\n"]}]},{"cell_type":"markdown","source":["## Creating Data Loaders"],"metadata":{"id":"9l3XaSkYqlUW"}},{"cell_type":"code","source":["SIZE = 256\n","class ColorizationDataset(Dataset):\n","    def __init__(self, paths, split='train'):\n","        if split == 'train':\n","            self.transforms = transforms.Compose([\n","                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n","                transforms.RandomHorizontalFlip(), # A little data augmentation!\n","            ])\n","        elif split == 'val':\n","            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n","        \n","        self.split = split\n","        self.size = SIZE\n","        self.paths = paths\n","    \n","    def __getitem__(self, idx):\n","        img = Image.open(self.paths[idx]).convert(\"RGB\")\n","        img = self.transforms(img)\n","        img = np.array(img)\n","        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n","        img_lab = transforms.ToTensor()(img_lab)\n","        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n","        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n","        \n","        return {'L': L, 'ab': ab}\n","    \n","    def __len__(self):\n","        return len(self.paths)\n","\n","def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, **kwargs): # A handy function to make our dataloaders\n","    dataset = ColorizationDataset(**kwargs)\n","    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n","                            pin_memory=pin_memory)\n","    return dataloader"],"metadata":{"id":"WJtgUdewoTNZ","executionInfo":{"status":"ok","timestamp":1651859100610,"user_tz":240,"elapsed":259,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_dl = make_dataloaders(paths=train_paths, split='train')\n","val_dl = make_dataloaders(paths=val_paths, split='val')\n","\n","data = next(iter(train_dl))\n","Ls, abs_ = data['L'], data['ab']\n","print(Ls.shape, abs_.shape)\n","print(len(train_dl), len(val_dl))"],"metadata":{"id":"RjNWqclEn0nO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651859108592,"user_tz":240,"elapsed":5482,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"3cad15d3-8b1c-428e-fc71-8e5236f754ba"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([16, 1, 256, 256]) torch.Size([16, 2, 256, 256])\n","500 125\n"]}]},{"cell_type":"markdown","source":["## Image Colorization Model(Training from Scratch)"],"metadata":{"id":"7FOm2Axlq0lk"}},{"cell_type":"markdown","source":["Generator: This code implements a UNet with ResNet18 backbone"],"metadata":{"id":"oLZoZlqZtGHA"}},{"cell_type":"code","source":["def build_res_unet(n_input=1, n_output=2, size=256):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n","    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n","    return net_G"],"metadata":{"id":"H9CooFR750M6","executionInfo":{"status":"ok","timestamp":1651859108593,"user_tz":240,"elapsed":7,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Patch Discriminator: This code implements a model by stacking blocks of Conv-BatchNorm-LeackyReLU."],"metadata":{"id":"C3qw98gArcxd"}},{"cell_type":"code","source":["class PatchDiscriminator(nn.Module):\n","    def __init__(self, input_c, num_filters=64, n_down=3):\n","        super().__init__()\n","        model = [self.get_layers(input_c, num_filters, norm=False)]\n","        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n","                          for i in range(n_down)] # the 'if' statement is taking care of not using\n","                                                  # stride of 2 for the last block in this loop\n","        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n","                                                                                             # activation for the last layer of the model\n","        self.model = nn.Sequential(*model)                                                   \n","        \n","    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n","        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n","        if norm: layers += [nn.BatchNorm2d(nf)]\n","        if act: layers += [nn.LeakyReLU(0.2, True)]\n","        return nn.Sequential(*layers)\n","    \n","    def forward(self, x):\n","        return self.model(x)"],"metadata":{"id":"w81s2ZhKr0o1","executionInfo":{"status":"ok","timestamp":1651859111095,"user_tz":240,"elapsed":2,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Loss Computations"],"metadata":{"id":"uYE285N7r5AY"}},{"cell_type":"code","source":["class GANLoss(nn.Module):\n","    def __init__(self, real_label=1.0, fake_label=0.0):\n","        super().__init__()\n","        self.register_buffer('real_label', torch.tensor(real_label))\n","        self.register_buffer('fake_label', torch.tensor(fake_label))\n","        self.loss = nn.BCEWithLogitsLoss()\n","    \n","    def get_labels(self, preds, target_is_real):\n","        if target_is_real:\n","            labels = self.real_label\n","        else:\n","            labels = self.fake_label\n","        return labels.expand_as(preds)\n","    \n","    def __call__(self, preds, target_is_real):\n","        labels = self.get_labels(preds, target_is_real)\n","        loss = self.loss(preds, labels)\n","        return loss"],"metadata":{"id":"8r5F-kvkuUP3","executionInfo":{"status":"ok","timestamp":1651859113537,"user_tz":240,"elapsed":264,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def init_weights(net, init='norm', gain=0.02):\n","    \n","    def init_func(m):\n","        classname = m.__class__.__name__\n","        if hasattr(m, 'weight') and 'Conv' in classname:\n","            if init == 'norm':\n","                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n","            elif init == 'xavier':\n","                nn.init.xavier_normal_(m.weight.data, gain=gain)\n","            elif init == 'kaiming':\n","                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","            \n","            if hasattr(m, 'bias') and m.bias is not None:\n","                nn.init.constant_(m.bias.data, 0.0)\n","        elif 'BatchNorm2d' in classname:\n","            nn.init.normal_(m.weight.data, 1., gain)\n","            nn.init.constant_(m.bias.data, 0.)\n","            \n","    net.apply(init_func)\n","    print(f\"model initialized with {init} initialization\")\n","    return net\n","\n","def init_model(model, device):\n","    model = model.to(device)\n","    model = init_weights(model)\n","    return model"],"metadata":{"id":"DW7T0OlVwZcI","executionInfo":{"status":"ok","timestamp":1651859115803,"user_tz":240,"elapsed":272,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Complete Conditional GAN architecture"],"metadata":{"id":"QHCv56bWsWM2"}},{"cell_type":"code","source":["class MainModel(nn.Module):\n","    def __init__(self, net_G, lr_G=2e-4, lr_D=2e-4, \n","                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n","        super().__init__()\n","        \n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.lambda_L1 = lambda_L1\n","        \n","        self.net_G = net_G.to(self.device)\n","        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n","        self.GANcriterion = GANLoss().to(self.device)\n","        self.L1criterion = nn.L1Loss()\n","        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n","        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n","    \n","    def set_requires_grad(self, model, requires_grad=True):\n","        for p in model.parameters():\n","            p.requires_grad = requires_grad\n","        \n","    def setup_input(self, data):\n","        self.L = data['L'].to(self.device)\n","        self.ab = data['ab'].to(self.device)\n","        \n","    def forward(self):\n","        self.fake_color = self.net_G(self.L)\n","    \n","    def backward_D(self):\n","        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n","        fake_preds = self.net_D(fake_image.detach())\n","        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n","        real_image = torch.cat([self.L, self.ab], dim=1)\n","        real_preds = self.net_D(real_image)\n","        self.loss_D_real = self.GANcriterion(real_preds, True)\n","        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n","        self.loss_D.backward()\n","    \n","    def backward_G(self):\n","        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n","        fake_preds = self.net_D(fake_image)\n","        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n","        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n","        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n","        self.loss_G.backward()\n","    \n","    def optimize(self):\n","        self.forward()\n","        self.net_D.train()\n","        self.set_requires_grad(self.net_D, True)\n","        self.opt_D.zero_grad()\n","        self.backward_D()\n","        self.opt_D.step()\n","        \n","        self.net_G.train()\n","        self.set_requires_grad(self.net_D, False)\n","        self.opt_G.zero_grad()\n","        self.backward_G()\n","        self.opt_G.step()"],"metadata":{"id":"2FJMj_FVweLx","executionInfo":{"status":"ok","timestamp":1651859118897,"user_tz":240,"elapsed":379,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Result Visualization"],"metadata":{"id":"hPiXqG6uskxW"}},{"cell_type":"code","source":["class AverageMeter:\n","    def __init__(self):\n","        self.reset()\n","        \n","    def reset(self):\n","        self.count, self.avg, self.sum = [0.] * 3\n","    \n","    def update(self, val, count=1):\n","        self.count += count\n","        self.sum += count * val\n","        self.avg = self.sum / self.count\n","\n","def create_loss_meters():\n","    loss_D_fake = AverageMeter()\n","    loss_D_real = AverageMeter()\n","    loss_D = AverageMeter()\n","    loss_G_GAN = AverageMeter()\n","    loss_G_L1 = AverageMeter()\n","    loss_G = AverageMeter()\n","    \n","    return {'loss_D_fake': loss_D_fake,\n","            'loss_D_real': loss_D_real,\n","            'loss_D': loss_D,\n","            'loss_G_GAN': loss_G_GAN,\n","            'loss_G_L1': loss_G_L1,\n","            'loss_G': loss_G}\n","\n","def update_losses(model, loss_meter_dict, count):\n","    for loss_name, loss_meter in loss_meter_dict.items():\n","        loss = getattr(model, loss_name)\n","        loss_meter.update(loss.item(), count=count)\n","\n","def lab_to_rgb(L, ab):\n","    \"\"\"\n","    Takes a batch of images\n","    \"\"\"\n","    \n","    L = (L + 1.) * 50.\n","    ab = ab * 110.\n","    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n","    rgb_imgs = []\n","    for img in Lab:\n","        img_rgb = lab2rgb(img)\n","        rgb_imgs.append(img_rgb)\n","    return np.stack(rgb_imgs, axis=0)\n","    \n","def visualize(model, data, batch_no,p, save=True):\n","    model.net_G.eval()\n","    with torch.no_grad():\n","        model.setup_input(data)\n","        model.forward()\n","    model.net_G.train()\n","    fake_color = model.fake_color.detach()\n","    real_color = model.ab\n","    L = model.L\n","    fake_imgs = lab_to_rgb(L, fake_color)\n","    real_imgs = lab_to_rgb(L, real_color)\n","    for k in range(0,16,4):\n","      fig = plt.figure(figsize=(15, 8))\n","      for i in range(4):\n","          ax = plt.subplot(3, 4, i + 1)\n","          ax.imshow(L[k+i][0].cpu(), cmap='gray')\n","          ax.axis(\"off\")\n","          ax = plt.subplot(3, 4, i + 1 + 4)\n","          ax.imshow(fake_imgs[k+i])\n","          ax.axis(\"off\")\n","          ax = plt.subplot(3, 4, i + 1 + 8)\n","          ax.imshow(real_imgs[k+i])\n","          ax.axis(\"off\")\n","          if save:\n","            im_fake=Image.fromarray(np.uint8(fake_imgs[k+i]*255))\n","            im_real_BW=ImageOps.grayscale(Image.fromarray(np.uint8(real_imgs[k+i]*255)))\n","            im_real_rgb=Image.fromarray(np.uint8(real_imgs[k+i]*255))\n","            if p == 1:\n","              im_fake.save(\"./colorized_images/LR_fake/image_\"+str(batch_no)+\"_\"+str(k+i)+\".png\")\n","              im_real_BW.save(\"./colorized_images/LR_real_bw/image_\"+str(batch_no)+\"_\"+str(k+i)+\".png\")\n","              im_real_rgb.save(\"./colorized_images/LR_real_rgb/image_\"+str(batch_no)+\"_\"+str(k+i)+\".png\")\n","            else:\n","              im_fake.save(\"./RealESRGAN_Results/supertocolor/image_\"+str(batch_no)+\"_\"+str(k+i)+\".png\")\n","              im_real_BW.save(\"./RealESRGAN_Results/super_bw/image_\"+str(batch_no)+\"_\"+str(k+i)+\".png\")\n","              im_real_rgb.save(\"./RealESRGAN_Results/super_rgb/image_\"+str(batch_no)+\"_\"+str(k+i)+\".png\")\n","      plt.show()\n","        \n","def log_results(loss_meter_dict):\n","    for loss_name, loss_meter in loss_meter_dict.items():\n","        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"],"metadata":{"id":"LLjfPjfr4KY7","executionInfo":{"status":"ok","timestamp":1651859125816,"user_tz":240,"elapsed":248,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Model Training"],"metadata":{"id":"2f2FNkW9ssat"}},{"cell_type":"code","source":["def train_model(model, train_dl, epochs, display_every=200):\n","    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intrvals\n","    for e in range(epochs):\n","        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to \n","        i = 0                                  # log the losses of the complete network\n","        for data in tqdm(train_dl):\n","            model.setup_input(data) \n","            model.optimize()\n","            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n","            i += 1\n","            if i % display_every == 0:\n","                print(f\"\\nEpoch {e+1}/{epochs}\")\n","                print(f\"Iteration {i}/{len(train_dl)}\")\n","                log_results(loss_meter_dict) # function to print out the losses\n","                visualize(model, data,batch_no=i,p=1, save=False) # function displaying the model's outputs"],"metadata":{"id":"BRTPYQcw5e08","executionInfo":{"status":"ok","timestamp":1651859132167,"user_tz":240,"elapsed":296,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n","    for e in range(epochs):\n","        loss_meter = AverageMeter()\n","        for data in tqdm(train_dl):\n","            L, ab = data['L'].to(device), data['ab'].to(device)\n","            preds = net_G(L)\n","            loss = criterion(preds, ab)\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            \n","            loss_meter.update(loss.item(), L.size(0))\n","            \n","        print(f\"Epoch {e + 1}/{epochs}\")\n","        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n","\n","net_G = build_res_unet(n_input=1, n_output=2, size=256) \n","opt = optim.Adam(net_G.parameters(), lr=1e-4)\n","criterion = nn.L1Loss()        \n","pretrain_generator(net_G, train_dl, opt, criterion, 20)\n","torch.save(net_G.state_dict(), \"res18-unet.pt\")"],"metadata":{"id":"-by1nTP17hYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net_G = build_res_unet(n_input=1, n_output=2, size=256)\n","net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n","model = MainModel(net_G=net_G)\n","train_model(model, train_dl, 20)\n","torch.save(model.state_dict(),\"color.pt\")"],"metadata":{"id":"sHyeLrT_7jV1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate"],"metadata":{"id":"xKBtk5Vs74nh"}},{"cell_type":"markdown","source":["Loading our pre-trained generator weights and GAN model."],"metadata":{"id":"6Sijs2MztdBw"}},{"cell_type":"code","source":["model_path_color = './color.pt'\n","net_G = build_res_unet(n_input=1, n_output=2, size=256)\n","net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n","model_color = MainModel(net_G=net_G)\n","model_color.load_state_dict(torch.load(model_path_color), strict=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["89da7f56af1d4baf9f52e6f9fa23bc56","aa80c3a711234fb88d63a1fc07652822","6affaf25d69540779e08537e0b369136","530358733e7f4b73a1ffbc685b9e08a2","ee51e2383552404890929c9db5f9ecdd","bf4eb12f0bf2453aa528b27283f6813e","8d5ba8f2546c4c96ba8547f80b0326c4","2501f57a2ced42028436ff85ffd6099e","cc206462c55d4611820a02d5c450ae90","8bdd3f2cd17c469893684969fb890f28","dbe11d355276405a865aa985ab782e1d"]},"id":"hBLhlsy679H9","executionInfo":{"status":"ok","timestamp":1651859159300,"user_tz":240,"elapsed":8118,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"eebbf3a1-960d-475a-8193-bf09459aceab"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89da7f56af1d4baf9f52e6f9fa23bc56"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["model initialized with norm initialization\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Pipeline 1: LR -> Color -> Super\n","\n"],"metadata":{"id":"39IKDseXWF6V"}},{"cell_type":"markdown","source":["Colorization:"],"metadata":{"id":"5oZALRSXWfTX"}},{"cell_type":"code","source":["custom_paths = './test_data/LR/'\n","\n","paths = glob.glob(custom_paths + \"/*.png\") # Grabbing all the image file names\n","\n","customval_paths = paths[:80]\n","\n","custom_dl = make_dataloaders(paths=customval_paths, split='val')\n","batch_no = 0\n","for d in tqdm(custom_dl):\n","  visualize(model_color, d, batch_no,p=1, save=True) # function displaying the model's outputs\n","  batch_no += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9654e59184a14eceb197793b9360d4ef","9b8c3a02927746d2bbf5fce63825476d","946446c880f445d0ac9326b39a87f65a","f6f36a1c5bb1433794cdd8342e921c8c","7e0d1fabafc54312ad09df8d2c011d5b","7f965d5833cf4f64bfafa364715d8b03","04ab005bc6ea4e369ae8c87d07682c3d","80770e5f41584a68ae549430bbfddad3","006ae423a4c0434aae3f0cccd040fde6","9198b984efb6441981c41ca7ec0edd80","d8230806f991497a980979b52507fdcf"],"output_embedded_package_id":"10O5pUK2N9_hVcmRWpAro4qCm6kgSNi-9"},"id":"LH8nsFoj0Ofw","executionInfo":{"status":"ok","timestamp":1651859330497,"user_tz":240,"elapsed":169148,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"f6d48539-0d48-463e-ed96-c06b9b747844"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Super Resolution:"],"metadata":{"id":"6pfm18GtG3lJ"}},{"cell_type":"code","source":["# if it is out of memory, try to use the `--tile` option\n","# We upsample the image with the scale factor X3.5\n","#os.chdir(\"./Real-ESRGAN\")\n","!python inference_realesrgan.py -n RealESRGAN_x4plus -i 'colorized_images/LR_fake' --outscale 3.5 --output 'RealESRGAN_Results/colortosuper'\n","# Arguments\n","# -n, --model_name: Model names\n","# -i, --input: input folder or image\n","# --outscale: Output scale, can be arbitrary scale factore. "],"metadata":{"id":"jPR0EcTvcs2W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651859456350,"user_tz":240,"elapsed":125921,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"1b7576f9-40b9-4dae-9e6e-9d51bc0cbe07"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing 0 image_0_0\n","Testing 1 image_0_1\n","Testing 2 image_0_10\n","Testing 3 image_0_11\n","Testing 4 image_0_12\n","Testing 5 image_0_13\n","Testing 6 image_0_14\n","Testing 7 image_0_15\n","Testing 8 image_0_2\n","Testing 9 image_0_3\n","Testing 10 image_0_4\n","Testing 11 image_0_5\n","Testing 12 image_0_6\n","Testing 13 image_0_7\n","Testing 14 image_0_8\n","Testing 15 image_0_9\n","Testing 16 image_1_0\n","Testing 17 image_1_1\n","Testing 18 image_1_10\n","Testing 19 image_1_11\n","Testing 20 image_1_12\n","Testing 21 image_1_13\n","Testing 22 image_1_14\n","Testing 23 image_1_15\n","Testing 24 image_1_2\n","Testing 25 image_1_3\n","Testing 26 image_1_4\n","Testing 27 image_1_5\n","Testing 28 image_1_6\n","Testing 29 image_1_7\n","Testing 30 image_1_8\n","Testing 31 image_1_9\n","Testing 32 image_2_0\n","Testing 33 image_2_1\n","Testing 34 image_2_10\n","Testing 35 image_2_11\n","Testing 36 image_2_12\n","Testing 37 image_2_13\n","Testing 38 image_2_14\n","Testing 39 image_2_15\n","Testing 40 image_2_2\n","Testing 41 image_2_3\n","Testing 42 image_2_4\n","Testing 43 image_2_5\n","Testing 44 image_2_6\n","Testing 45 image_2_7\n","Testing 46 image_2_8\n","Testing 47 image_2_9\n","Testing 48 image_3_0\n","Testing 49 image_3_1\n","Testing 50 image_3_10\n","Testing 51 image_3_11\n","Testing 52 image_3_12\n","Testing 53 image_3_13\n","Testing 54 image_3_14\n","Testing 55 image_3_15\n","Testing 56 image_3_2\n","Testing 57 image_3_3\n","Testing 58 image_3_4\n","Testing 59 image_3_5\n","Testing 60 image_3_6\n","Testing 61 image_3_7\n","Testing 62 image_3_8\n","Testing 63 image_3_9\n","Testing 64 image_4_0\n","Testing 65 image_4_1\n","Testing 66 image_4_10\n","Testing 67 image_4_11\n","Testing 68 image_4_12\n","Testing 69 image_4_13\n","Testing 70 image_4_14\n","Testing 71 image_4_15\n","Testing 72 image_4_2\n","Testing 73 image_4_3\n","Testing 74 image_4_4\n","Testing 75 image_4_5\n","Testing 76 image_4_6\n","Testing 77 image_4_7\n","Testing 78 image_4_8\n","Testing 79 image_4_9\n","Testing 80 image_5_0\n","Testing 81 image_5_1\n","Testing 82 image_5_10\n","Testing 83 image_5_11\n","Testing 84 image_5_12\n","Testing 85 image_5_13\n","Testing 86 image_5_14\n","Testing 87 image_5_15\n","Testing 88 image_5_2\n","Testing 89 image_5_3\n","Testing 90 image_5_4\n","Testing 91 image_5_5\n","Testing 92 image_5_6\n","Testing 93 image_5_7\n","Testing 94 image_5_8\n","Testing 95 image_5_9\n","Testing 96 image_6_0\n","Testing 97 image_6_1\n","Testing 98 image_6_2\n","Testing 99 image_6_3\n"]}]},{"cell_type":"markdown","source":["## Pipeline 2: LR -> Super -> Color"],"metadata":{"id":"Vuk2WpoAW5yV"}},{"cell_type":"markdown","source":["Super Resolution:"],"metadata":{"id":"5BTdCWnCXDFy"}},{"cell_type":"code","source":["test_img_folder = './test_data/LR/*' #Either colored image or LR image path"],"metadata":{"id":"N-jKh1IXXU9J","executionInfo":{"status":"ok","timestamp":1651859456351,"user_tz":240,"elapsed":15,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# if it is out of memory, try to use the `--tile` option\n","# We upsample the image with the scale factor X3.5\n","!python inference_realesrgan.py -n RealESRGAN_x4plus -i 'test_data/LR' --outscale 3.5 --output 'RealESRGAN_Results/LRtosuper/'\n","# Arguments\n","# -n, --model_name: Model names\n","# -i, --input: input folder or image\n","# --outscale: Output scale, can be arbitrary scale factore. "],"metadata":{"id":"cZXuMQE1W-OK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651859537572,"user_tz":240,"elapsed":81234,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"06d25a1d-e33f-48f7-de10-188facec5fdb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing 0 0\n","Testing 1 1\n","Testing 2 10\n","Testing 3 11\n","Testing 4 12\n","Testing 5 13\n","Testing 6 14\n","Testing 7 15\n","Testing 8 16\n","Testing 9 17\n","Testing 10 18\n","Testing 11 19\n","Testing 12 2\n","Testing 13 20\n","Testing 14 21\n","Testing 15 22\n","Testing 16 23\n","Testing 17 24\n","Testing 18 25\n","Testing 19 26\n","Testing 20 27\n","Testing 21 28\n","Testing 22 29\n","Testing 23 3\n","Testing 24 30\n","Testing 25 31\n","Testing 26 32\n","Testing 27 33\n","Testing 28 34\n","Testing 29 35\n","Testing 30 36\n","Testing 31 37\n","Testing 32 38\n","Testing 33 39\n","Testing 34 4\n","Testing 35 40\n","Testing 36 41\n","Testing 37 42\n","Testing 38 43\n","Testing 39 44\n","Testing 40 45\n","Testing 41 46\n","Testing 42 47\n","Testing 43 48\n","Testing 44 49\n","Testing 45 5\n","Testing 46 50\n","Testing 47 51\n","Testing 48 52\n","Testing 49 53\n","Testing 50 54\n","Testing 51 55\n","Testing 52 56\n","Testing 53 57\n","Testing 54 58\n","Testing 55 59\n","Testing 56 6\n","Testing 57 60\n","Testing 58 61\n","Testing 59 62\n","Testing 60 63\n","Testing 61 64\n","Testing 62 65\n","Testing 63 66\n","Testing 64 67\n","Testing 65 68\n","Testing 66 69\n","Testing 67 7\n","Testing 68 70\n","Testing 69 71\n","Testing 70 72\n","Testing 71 73\n","Testing 72 74\n","Testing 73 75\n","Testing 74 76\n","Testing 75 77\n","Testing 76 78\n","Testing 77 79\n","Testing 78 8\n","Testing 79 80\n","Testing 80 81\n","Testing 81 82\n","Testing 82 83\n","Testing 83 84\n","Testing 84 85\n","Testing 85 86\n","Testing 86 87\n","Testing 87 88\n","Testing 88 89\n","Testing 89 9\n","Testing 90 90\n","Testing 91 91\n","Testing 92 92\n","Testing 93 93\n","Testing 94 94\n","Testing 95 95\n","Testing 96 96\n","Testing 97 97\n","Testing 98 98\n","Testing 99 99\n"]}]},{"cell_type":"markdown","source":["Colorization:"],"metadata":{"id":"ojjkzMwHXqyM"}},{"cell_type":"code","source":["custom_paths = './RealESRGAN_Results/LRtosuper/'\n","\n","paths = glob.glob(custom_paths + \"/*.png\") # Grabbing all the image file names\n","customval_paths = paths[:80]\n","\n","custom_dl = make_dataloaders(paths=customval_paths, split='val')\n","batch_no = 0\n","for d in tqdm(custom_dl):\n","  visualize(model_color, d, batch_no,p=0, save=True) # function displaying the model's outputs\n","  batch_no += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["48878e1d93bc47cb94d48c6cec2f255f","48a4d5c12af2418e838d6629a3a5d57d","91a4e985e06040d8bcd924df4f61eb1b","b53cad15862a4f3b81e9ed991c69ed38","89a6bbf2a6814e1bbe1a34a3ea88ba1c","8650c09fa1e74766ba952ff2e08dcfc1","cf6f0d364dfd41ce8c15591a2e8ba6ba","9f1cada8702c4fa981d16e3c41f33d43","48ebbd94a27c4211afadfb2a8fd11f7e","b1cc714fd75841468964459ed044773f","385a0f646da943d28fe0145fe37dc0b5"],"output_embedded_package_id":"1YJ3WaebaTqKL20jN2so1dyEhklE92ETZ"},"id":"-gzi0MMhXs5W","executionInfo":{"status":"ok","timestamp":1651859721282,"user_tz":240,"elapsed":183726,"user":{"displayName":"Radhika Lakhkar","userId":"04557589146148033111"}},"outputId":"5baf762e-41d7-4a1d-c5b2-553c27f686f4"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"colab":{"machine_shape":"hm","name":"ColorizationRealESR.ipynb","provenance":[{"file_id":"https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/Image%20Colorization%20with%20U-Net%20and%20GAN%20Tutorial.ipynb","timestamp":1650828019154}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"89da7f56af1d4baf9f52e6f9fa23bc56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa80c3a711234fb88d63a1fc07652822","IPY_MODEL_6affaf25d69540779e08537e0b369136","IPY_MODEL_530358733e7f4b73a1ffbc685b9e08a2"],"layout":"IPY_MODEL_ee51e2383552404890929c9db5f9ecdd"}},"aa80c3a711234fb88d63a1fc07652822":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf4eb12f0bf2453aa528b27283f6813e","placeholder":"​","style":"IPY_MODEL_8d5ba8f2546c4c96ba8547f80b0326c4","value":"100%"}},"6affaf25d69540779e08537e0b369136":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2501f57a2ced42028436ff85ffd6099e","max":46830571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc206462c55d4611820a02d5c450ae90","value":46830571}},"530358733e7f4b73a1ffbc685b9e08a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bdd3f2cd17c469893684969fb890f28","placeholder":"​","style":"IPY_MODEL_dbe11d355276405a865aa985ab782e1d","value":" 44.7M/44.7M [00:01&lt;00:00, 39.4MB/s]"}},"ee51e2383552404890929c9db5f9ecdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf4eb12f0bf2453aa528b27283f6813e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d5ba8f2546c4c96ba8547f80b0326c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2501f57a2ced42028436ff85ffd6099e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc206462c55d4611820a02d5c450ae90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bdd3f2cd17c469893684969fb890f28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbe11d355276405a865aa985ab782e1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9654e59184a14eceb197793b9360d4ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b8c3a02927746d2bbf5fce63825476d","IPY_MODEL_946446c880f445d0ac9326b39a87f65a","IPY_MODEL_f6f36a1c5bb1433794cdd8342e921c8c"],"layout":"IPY_MODEL_7e0d1fabafc54312ad09df8d2c011d5b"}},"9b8c3a02927746d2bbf5fce63825476d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f965d5833cf4f64bfafa364715d8b03","placeholder":"​","style":"IPY_MODEL_04ab005bc6ea4e369ae8c87d07682c3d","value":"100%"}},"946446c880f445d0ac9326b39a87f65a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80770e5f41584a68ae549430bbfddad3","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_006ae423a4c0434aae3f0cccd040fde6","value":5}},"f6f36a1c5bb1433794cdd8342e921c8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9198b984efb6441981c41ca7ec0edd80","placeholder":"​","style":"IPY_MODEL_d8230806f991497a980979b52507fdcf","value":" 5/5 [02:45&lt;00:00, 31.25s/it]"}},"7e0d1fabafc54312ad09df8d2c011d5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f965d5833cf4f64bfafa364715d8b03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04ab005bc6ea4e369ae8c87d07682c3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80770e5f41584a68ae549430bbfddad3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"006ae423a4c0434aae3f0cccd040fde6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9198b984efb6441981c41ca7ec0edd80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8230806f991497a980979b52507fdcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48878e1d93bc47cb94d48c6cec2f255f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48a4d5c12af2418e838d6629a3a5d57d","IPY_MODEL_91a4e985e06040d8bcd924df4f61eb1b","IPY_MODEL_b53cad15862a4f3b81e9ed991c69ed38"],"layout":"IPY_MODEL_89a6bbf2a6814e1bbe1a34a3ea88ba1c"}},"48a4d5c12af2418e838d6629a3a5d57d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8650c09fa1e74766ba952ff2e08dcfc1","placeholder":"​","style":"IPY_MODEL_cf6f0d364dfd41ce8c15591a2e8ba6ba","value":"100%"}},"91a4e985e06040d8bcd924df4f61eb1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f1cada8702c4fa981d16e3c41f33d43","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48ebbd94a27c4211afadfb2a8fd11f7e","value":5}},"b53cad15862a4f3b81e9ed991c69ed38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1cc714fd75841468964459ed044773f","placeholder":"​","style":"IPY_MODEL_385a0f646da943d28fe0145fe37dc0b5","value":" 5/5 [03:03&lt;00:00, 36.47s/it]"}},"89a6bbf2a6814e1bbe1a34a3ea88ba1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8650c09fa1e74766ba952ff2e08dcfc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf6f0d364dfd41ce8c15591a2e8ba6ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f1cada8702c4fa981d16e3c41f33d43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48ebbd94a27c4211afadfb2a8fd11f7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1cc714fd75841468964459ed044773f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"385a0f646da943d28fe0145fe37dc0b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}